<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>howto/userguide-data-pipelines · eMagiz Platform documentation</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="# Data pipelining in eMagiz"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="howto/userguide-data-pipelines · eMagiz Platform documentation"/><meta property="og:type" content="website"/><meta property="og:url" content="https://emagiz.github.io/"/><meta property="og:description" content="# Data pipelining in eMagiz"/><meta name="twitter:card" content="summary"/><link rel="shortcut icon" href="/img/platypus.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/platypus.png" alt="eMagiz Platform documentation"/><h2 class="headerTitleWithLogo">eMagiz Platform documentation</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Ask me something" title="Ask me something"/></li><li class=""><a href="/docs/referenceguide/" target="_self">Reference Guide</a></li><li class=""><a href="/docs/microlearning/" target="_self">eMagiz Academy</a></li><li class=""><a href="/docs/howto/" target="_self">User Guides</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 id="__docusaurus" class="postHeaderTitle">howto/userguide-data-pipelines</h1></header><article><div><span><h1><a class="anchor" aria-hidden="true" id="data-pipelining-in-emagiz"></a><a href="#data-pipelining-in-emagiz" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data pipelining in eMagiz</h1>
<h2><a class="anchor" aria-hidden="true" id="1-introduction"></a><a href="#1-introduction" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>1. Introduction</h2>
<p>In this document we take a look at implementing a data pipeline within eMagiz to support your business case. eMagiz data pipelines are flows that support high-volume data transfer using <a href="_new">Spring Batch</a> technology.</p>
<p>The document is structured as follows:</p>
<ul>
<li>A quick overview of what a data pipeline can do and can not do for you</li>
<li>Take a look at the options you have as input and output of a data pipeline</li>
<li>Mendix to AWS Redshift example</li>
<li>Job Dashboard and the configuration of the dashboard</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="2-data-pipelines-in-emagiz"></a><a href="#2-data-pipelines-in-emagiz" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2. Data pipelines in eMagiz</h2>
<p>A data pipeline connects a input and output stream without any or minimal transformation. This leads to the following advantages and disadvantages.</p>
<p>Advantages of eMagiz data pipelines</p>
<ul>
<li>Supports very large tables</li>
<li>Fast Mendix to Redshift-integration development compared to message bus integrations</li>
</ul>
<p>Disadvantages of eMagiz data pipelines</p>
<ul>
<li>Does not support complex data structures (one table per data pipeline)</li>
<li>Does not support complex transformations (only column selection/renaming)</li>
<li>Data structure changes need to be applied to both source and target tables</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="3-input-and-output-options"></a><a href="#3-input-and-output-options" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>3. Input and output options</h2>
<p>Within eMagiz we support the following options for input and output of the data pipeline</p>
<p>Input</p>
<ul>
<li>Flat file item reader (csv)</li>
<li>Odata v3 item reader (Mendix)</li>
</ul>
<p>Output</p>
<ul>
<li>Azure Event Hubs item writer</li>
<li>JDBC batch item writer</li>
<li>Amazon Redshift item writer</li>
<li>Remote flat file item writer</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="4-mendix-to-aws-redshift-example"></a><a href="#4-mendix-to-aws-redshift-example" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>4. Mendix to AWS Redshift Example</h2>
<h3><a class="anchor" aria-hidden="true" id="41-getting-started"></a><a href="#41-getting-started" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>4.1 Getting started</h3>
<ol>
<li>Publish the data using an OData service in your Mendix project.</li>
<li>Use the Mendix PostgreSQL data structure to create the target table in Redshift (Recommended).</li>
<li>Import the 'Mendix to Redshift' datapipeline flow from the store.
   <p align="center"><img src="../../img/howto/datapipeline-store-item.png"></p>
1. Follow the store items instructions to setup the data pipeline.
1. Follow the rest of this how-to to start using AWS materialized views.
</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="42-create-a-materialized-view"></a><a href="#42-create-a-materialized-view" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>4.2 Create a materialized view</h3>
<ol>
<li>Use SQL Workbench or the AWS Console to connect to the Redshift database.</li>
<li>Write and test the SQL statement to select data from the Redshift database. If you need help joining tables look at the
<a target="_new" href="https://www.w3schools.com/sql/sql_join_inner.asp">w3school tutorials</a>.</li>
<li>Execute the following statement to create the materialized view:</br>
<code>CREATE MATERIALIZED VIEW {viewname} AS {your query};</code>
<p align="center"><img  src="../../img/howto/datapipeline-create-materialized-view.png"></p></li>
<li>For more info see the AWS documentation:
<a target="_new" href="https://docs.aws.amazon.com/redshift/latest/dg/materialized-view-overview.html">Creating materialized views in Amazon Redshift</a></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="43-refresh-the-materialized-view"></a><a href="#43-refresh-the-materialized-view" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>4.3 Refresh the materialized view</h3>
<ol>
<li>The example data pipeline flow from the store contains a job listener structure to refresh the AWS Materialized view after the job is complete. In this structure the <i>send.jdbc-refresh</i> component send the <code>REFRESH MATERIALIZED VIEW</code> command to AWS Redshift.
<p align="center"><img  src="../../img/howto/datapipeline-listener-structure.png"></p></li>
<li>It is highly recommended to have only one data pipeline in one eMagiz flow. If you have materialized views using data from different data pipelines, by default, the materialized view will be refreshed after each pipeline. If this causes invalid data in the materialized view, consider removing the refresh structure from all but the last scheduled data pipeline.</li>
<li>In case you are not using a Materialized View from the standard Store component, you have the option to remove this section alltogether or change the SQL statement where the refresh takes place to a non-functional (such as SELECT NOW() or SELECT true).</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="44-delete-the-materialized-view"></a><a href="#44-delete-the-materialized-view" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>4.4 Delete the Materialized view</h3>
<ol>
<li>Use SQL Workbench or the AWS Console to connect to the Redshift database.</li>
<li>Execute the following statement to delete the materialized view:</br>
<code>DROP MATERIALIZED VIEW {viewname};</code></li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="5-job-dashboard-data-pipeline"></a><a href="#5-job-dashboard-data-pipeline" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>5. Job dashboard data pipeline</h2>
<p>On this page we will explain a bit on the job dashboard functionality within eMagiz</p>
<h3><a class="anchor" aria-hidden="true" id="51-job-dashboard"></a><a href="#51-job-dashboard" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>5.1 Job dashboard</h3>
<p>On runtime level within the runtime dashboard a button named Jobs is available for users that make use of one or more data pipeline solutions within their respective eMagiz projects. By clicking on this button after you have selected a specific flow you get an overview of the Job executions of that flow.</p>
<p align="center"><img src="../../img/howto/job-dashboard-data-pipeline-0.png"></p>
<h3><a class="anchor" aria-hidden="true" id="52-explaining-the-inner-workings-of-the-job-dashboard"></a><a href="#52-explaining-the-inner-workings-of-the-job-dashboard" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>5.2 Explaining the inner workings of the Job Dashboard</h3>
<p>By clicking on the Job dashboard you send a command to the flow you have selected in your runtime dashboard. This flow receives the command and thereby activates the job manager.</p>
<p align="center"><img src="../../img/howto/job-dashboard-data-pipeline-1.png"></p>
<p>The job manager in turn will look in the H2 database linked to that specific flow for relevant information on the executions of jobs via the data pipeline solutions.</p>
<p>This information is then showed to the user via a popup were you can see all executions and see the details of executions when you click through them</p>
<p align="center"><img src="../../img/howto/job-dashboard-data-pipeline-2.png"></p>
<h3><a class="anchor" aria-hidden="true" id="best-practices"></a><a href="#best-practices" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Best practices</h3>
<ul>
<li>Create a separate H2 database per data pipeline you build within your project. For example if you have 10 data pipelines you should create 10 separate H2 databases. As stated in the documentation of the store component:
<ul>
<li>dp.h2.message.database; database name for the local h2 database (eg: &quot;batch&quot;). When using multiple pipeline flows on one container, consider renaming this property by replacing 'message' with the corresponding message type name in the 'support.h2-database' component.</li>
</ul></li>
<li>Clean up the H2 database on a periodic basis to keep its contents in check to prevent that the Job dashboard will stop functioning</li>
<li>Use the Job dashboard in conjuction with the Manage phase to monitor and set up alerting surrounding the performance of the data pipeline solutions</li>
</ul>
</span></div></article></div><div class="docs-prevnext"></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#1-introduction">1. Introduction</a></li><li><a href="#2-data-pipelines-in-emagiz">2. Data pipelines in eMagiz</a></li><li><a href="#3-input-and-output-options">3. Input and output options</a></li><li><a href="#4-mendix-to-aws-redshift-example">4. Mendix to AWS Redshift Example</a><ul class="toc-headings"><li><a href="#41-getting-started">4.1 Getting started</a></li><li><a href="#42-create-a-materialized-view">4.2 Create a materialized view</a></li><li><a href="#43-refresh-the-materialized-view">4.3 Refresh the materialized view</a></li><li><a href="#44-delete-the-materialized-view">4.4 Delete the Materialized view</a></li></ul></li><li><a href="#5-job-dashboard-data-pipeline">5. Job dashboard data pipeline</a><ul class="toc-headings"><li><a href="#51-job-dashboard">5.1 Job dashboard</a></li><li><a href="#52-explaining-the-inner-workings-of-the-job-dashboard">5.2 Explaining the inner workings of the Job Dashboard</a></li><li><a href="#best-practices">Best practices</a></li></ul></li></ul></nav></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '2e1804e3e0c239242d9914d98d6bf260',
                indexName: 'emagiz',
                inputSelector: '#search_input_react'
              });
            </script></body></html>